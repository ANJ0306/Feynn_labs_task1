{
  "cells": [
    {
      "metadata": {
        "id": "TmOOiehKyg7v"
      },
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries <a name=\"ImportingLibraries\"></a>"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsTCAGhSyg7v",
        "outputId": "c4b1b8a9-4947-4cbc-a8aa-9f988ca7caf4"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np # linear algebra\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Device:', tpu.master())\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of replicas: 1\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sormKArtyg7w",
        "outputId": "40eb501e-f226-42c6-9c4a-59eca1f4e950",
        "collapsed": true
      },
      "cell_type": "code",
      "source": [
        "print(\"Version \", tf.__version__)\n",
        "print(\"Eager mode:\", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\",\"available\" if tf.test.is_gpu_available() else\"Not Available\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-2b9eb71e9dba>:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version  2.15.0\n",
            "Eager mode: True\n",
            "Hub version:  0.16.1\n",
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "TzqA4qXPyg7w"
      },
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset <a name=\"LoadingDataset\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "8SRka4vl11Uc",
        "outputId": "efe53c80-5674-4234-e534-def7b188e8eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-bf1647b42bbd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/python\n",
        "\n",
        "import os, sys\n",
        "\n",
        "# Create new Train and val folders\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/rice_images'\n",
        "train_path = '/content/drive/MyDrive/rice_images'\n",
        "val_path = '/content/drive/MyDrive/rice_images'\n",
        "\n",
        "column_names = os.listdir(train_path)\n",
        "for i in column_names:\n",
        "    # The exist_ok=True flag tells makedirs to ignore the error if the directory already exists.\n",
        "    os.makedirs(f'/content/drive/MyDrive/rice_images/output/train/{i}', exist_ok=True)\n",
        "    os.makedirs(f'/content/drive/MyDrive/rice_images/output/validation/{i}', exist_ok=True)\n",
        "\n",
        "out_path = '../kaggle/output/train/'"
      ],
      "metadata": {
        "id": "t94uYMKxZ-JX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9EGWEwC4yg7w"
      },
      "cell_type": "markdown",
      "source": [
        "# Resizing Image [OPTIONAL]  <a name=\"Resize\"></a>"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "VtlFSqvSyg7w"
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "def resize(input_path,folder,column_name):\n",
        "    dirs = os.listdir(input_path)\n",
        "    for item in dirs:\n",
        "        item_path = input_path +'/' +item\n",
        "        if os.path.isfile(item_path):\n",
        "            #print('CHECK')\n",
        "            im = Image.open(item_path)\n",
        "\n",
        "            # Check whether the specified\n",
        "            # path exists or not\n",
        "            outpath = f'/content/drive/MyDrive/rice_images/output/{folder}/{column_name}'\n",
        "            temp_out_path = outpath+'/'+item\n",
        "            f, e = os.path.splitext(temp_out_path)\n",
        "\n",
        "            imResize = im.resize((255,255), Image.ANTIALIAS)\n",
        "            #print('CHECK 3')\n",
        "            imResize.save(f + '.jpg', 'JPEG', quality=90)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "PoziuqNZyg7x"
      },
      "cell_type": "code",
      "source": [
        "input_path = '/content/drive/MyDrive/rice_images/_Healthy'\n",
        "folder = 'train'\n",
        "column_name = 'Healthy'\n",
        "resize(input_path,folder,column_name)\n",
        "\n",
        "input_path = '/content/drive/MyDrive/rice_images/_BrownSpot'\n",
        "folder = 'train'\n",
        "column_name = 'BrownSpot'\n",
        "resize(input_path,folder,column_name)\n",
        "\n",
        "input_path = '/content/drive/MyDrive/rice_images/_Hispa'\n",
        "folder = 'train'\n",
        "column_name = 'Hispa'\n",
        "resize(input_path,folder,column_name)\n",
        "\n",
        "input_path = '/content/drive/MyDrive/rice_images/_Hispa/_LeafBlast'\n",
        "folder = 'train'\n",
        "column_name = 'LeafBlast'\n",
        "resize(input_path,folder,column_name)\n",
        "\n",
        "print('Done with train resizing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "y0NvCBfhyg7x"
      },
      "cell_type": "code",
      "source": [
        "## VALIDATION\n",
        "input_path = '/content/drive/MyDrive/rice_images/_Healthy'\n",
        "folder = 'validation'\n",
        "column_name = 'Healthy'\n",
        "resize(input_path,folder,column_name)\n",
        "\n",
        "input_path = '/content/drive/MyDrive/rice_images/_BrownSpot'\n",
        "folder = 'validation'\n",
        "column_name = 'BrownSpot'\n",
        "resize(input_path,folder,column_name)\n",
        "\n",
        "input_path = '/content/drive/MyDrive/rice_images/_Hispa'\n",
        "folder = 'validation'\n",
        "column_name = 'Hispa'\n",
        "resize(input_path,folder,column_name)\n",
        "\n",
        "input_path = '/content/drive/MyDrive/rice_images/_Hispa/_LeafBlast'\n",
        "folder = 'validation'\n",
        "column_name = 'LeafBlast'\n",
        "resize(input_path,folder,column_name)\n",
        "\n",
        "print('Done with Validation resizing')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "SnRSGS8_yg7x"
      },
      "cell_type": "code",
      "source": [
        "os.path.exists('/content/drive/MyDrive/rice_images/output/validation/Healthy/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "A22yk_N0yg7x"
      },
      "cell_type": "code",
      "source": [
        "os.path.exists('/content/drive/MyDrive/rice_images/output/train/')\n",
        "os.path.exists('/content/drive/MyDrive/rice_images/output/validation/')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# ... your existing code ...\n",
        "\n",
        "resize(input_path, folder, column_name)\n",
        "\n",
        "# Check if the output directory exists\n",
        "output_dir = os.path.join('/content/drive/MyDrive/rice_images/output', folder, column_name)\n",
        "if os.path.exists(output_dir):\n",
        "    print(f\"Output directory created: {output_dir}\")\n",
        "else:\n",
        "    print(f\"Output directory not found: {output_dir}\")\n",
        "\n",
        "# ... your existing code ."
      ],
      "metadata": {
        "id": "VX0xd8ebaQZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "bQ7t1NEoyg7x"
      },
      "cell_type": "code",
      "source": [
        "data_dir = os.path.join(os.path.dirname('/content/drive/MyDrive/rice_images'), 'output')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NoYwEHplyg7x"
      },
      "cell_type": "markdown",
      "source": [
        "# Split into Training and Validation  <a name=\"Split\"></a>"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "xUjiVmaryg7x"
      },
      "cell_type": "code",
      "source": [
        "# Use this if you avoided the resizing\n",
        "data_dir = os.path.join(os.path.dirname('/output/'), 'RiceLeafs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "HykeGsWFyg7y"
      },
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(data_dir, 'train')\n",
        "train_BrownSpot_dir = os.path.join(train_dir, 'BrownSpot')\n",
        "train_Healthy_dir = os.path.join(train_dir, 'Healthy')\n",
        "train_Hispa_dir = os.path.join(train_dir, 'Hispa')\n",
        "train_LeafBlast_dir = os.path.join(train_dir, 'LeafBlast')\n",
        "\n",
        "\n",
        "validation_dir = os.path.join(data_dir, 'validation')\n",
        "validation_BrownSpot_dir = os.path.join(validation_dir, 'BrownSpot')\n",
        "validation_Healthy_dir = os.path.join(validation_dir, 'Healthy')\n",
        "validation_Hispa_dir = os.path.join(validation_dir, 'Hispa')\n",
        "validation_LeafBlast_dir = os.path.join(validation_dir, 'LeafBlast')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Verify the correct path to your data directory\n",
        "data_dir = '/path/to/your/RiceLeafs'  # Replace with the actual path\n",
        "\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "\n",
        "# Check if the 'BrownSpot' directory exists within the 'train' directory\n",
        "if not os.path.exists(os.path.join(train_dir, 'BrownSpot')):\n",
        "    print(\"Error: 'BrownSpot' directory not found within the 'train' directory.\")\n",
        "else:\n",
        "    train_BrownSpot_dir = os.path.join(train_dir, 'BrownSpot')\n",
        "    train_BrownSpot_names = os.listdir(train_BrownSpot_dir)\n",
        "    print(train_BrownSpot_names[:10])"
      ],
      "metadata": {
        "id": "OmFHXfkFadZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZzrmcWWeyg7y"
      },
      "cell_type": "markdown",
      "source": [
        "## Image Count <a name=\"ImageCount\"></a>"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "BiJ639YDyg7y"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "import os\n",
        "from os.path import exists\n",
        "\n",
        "def count(dir, counter=0):\n",
        "    \"returns number of files in dir and subdirs\"\n",
        "    for pack in os.walk(dir):\n",
        "        for f in pack[2]:\n",
        "            counter += 1\n",
        "    return dir + \" : \" + str(counter) + \" files\"\n",
        "\n",
        "print('total images for training :', count(train_dir))\n",
        "print('total images for validation :', count(validation_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jN0upje1yg7y"
      },
      "cell_type": "markdown",
      "source": [
        "## Viewing Images  <a name=\"ViewingImages\"></a>"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Lq-Nvlvsyg7y"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "\n",
        "# Parameters for our graph; we'll outpu images in a 4x4 configuration\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "# for iternating over images\n",
        "pic_index = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols *4, nrows*4)\n",
        "\n",
        "pic_index += 8\n",
        "\n",
        "# Define or import train_BrownSpot_names here.\n",
        "# For example, if it's a list of filenames:\n",
        "train_BrownSpot_names = [\"image1.jpg\", \"image2.jpg\", ...]\n",
        "\n",
        "next_BrownSpot_pix = [os.path.join(train_BrownSpot_dir, fname)\n",
        "                for fname in train_BrownSpot_names[pic_index-8:pic_index]]\n",
        "\n",
        "for i, img_path in enumerate(next_BrownSpot_pix):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows,ncols,i +1)\n",
        "  #sp.axis('Off') # Don't show axes (or gridlines)\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PzyAgSTh7voP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HIij1hjWyg7y"
      },
      "cell_type": "markdown",
      "source": [
        "### BrownSpot <a name=\"BrownSpot\"></a>"
      ]
    },
    {
      "metadata": {
        "id": "AMCLB2ysyg7y"
      },
      "cell_type": "markdown",
      "source": [
        "### Healthy <a name=\"Healthy\"></a>"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "iOII17ufyg7y"
      },
      "cell_type": "code",
      "source": [
        "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols *4, nrows*4)\n",
        "\n",
        "pic_index += 8\n",
        "next_Healthy_pix = [os.path.join(train_Healthy_dir, fname)\n",
        "                for fname in train_Healthy_names[pic_index-8:pic_index]]\n",
        "\n",
        "\n",
        "for i, img_path in enumerate(next_Healthy_pix):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows,ncols,i +1)\n",
        "  #sp.axis('Off') # Don't show axes (or gridlines)\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r0hbvs7uyg7z"
      },
      "cell_type": "markdown",
      "source": [
        "### Hispa <a name=\"Hispa\"></a>"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "6GgN4yJbyg7z"
      },
      "cell_type": "code",
      "source": [
        "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols *4, nrows*4)\n",
        "\n",
        "pic_index += 8\n",
        "\n",
        "next_Hispa_pix = [os.path.join(train_Hispa_dir, fname)\n",
        "                for fname in train_Hispa_names[pic_index-8:pic_index]]\n",
        "\n",
        "\n",
        "for i, img_path in enumerate(next_Hispa_pix):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows,ncols,i +1)\n",
        "  #sp.axis('Off') # Don't show axes (or gridlines)\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GGKcsQxgyg7z"
      },
      "cell_type": "markdown",
      "source": [
        "### LeafBlast <a name=\"LeafBlast\"></a>"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "cfUctwYvyg7z"
      },
      "cell_type": "code",
      "source": [
        "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols *4, nrows*4)\n",
        "\n",
        "pic_index += 8\n",
        "\n",
        "next_LeafBlast_pix = [os.path.join(train_LeafBlast_dir, fname)\n",
        "                for fname in train_LeafBlast_names[pic_index-8:pic_index]]\n",
        "\n",
        "for i, img_path in enumerate(next_LeafBlast_pix):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows,ncols,i +1)\n",
        "  #sp.axis('Off') # Don't show axes (or gridlines)\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PPBaqMPryg7z"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation and Generators <a name=\"DataAugAndGen\"></a>"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "j5y1AxSvyg7z"
      },
      "cell_type": "code",
      "source": [
        "IMAGE_SHAPE = (244, 244)\n",
        "BATCH_SIZE = 64 #@param {type:\"integer\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "khZOSAFayg7z"
      },
      "cell_type": "code",
      "source": [
        "# Inputs are suitably resized for the selected module. Dataset augmentation (i.e., random distortions of an image each time it is read) improves training, esp. when fine-tuning.\n",
        "\n",
        "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    shuffle=False,\n",
        "    seed=42,\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "do_data_augmentation = True #@param {type:\"boolean\"}\n",
        "if do_data_augmentation:\n",
        "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      rotation_range=40,\n",
        "      horizontal_flip=True,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      fill_mode='nearest' )\n",
        "else:\n",
        "  train_datagen = validation_datagen\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=IMAGE_SHAPE,\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "v9pthdRQyg7z"
      },
      "cell_type": "code",
      "source": [
        "train_generator.num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wX7DT_A4yg7z"
      },
      "cell_type": "markdown",
      "source": [
        "## Callback <a name=\"Callback\"></a>"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "cFx4QmAJyg70"
      },
      "cell_type": "code",
      "source": [
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self,epoch,log = {}):\n",
        "    if(log.get('accuracy')> 0.99):\n",
        "      if(log.get('val_accuracy')>0.99):\n",
        "        print(\"\\n Reached 99% Accuracy for both train and val.\")\n",
        "        self.model.stop_training = True\n",
        "\n",
        "callbacks = MyCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9laODOLVyg70"
      },
      "cell_type": "markdown",
      "source": [
        "# Models <a name=\"Model\"></a>"
      ]
    },
    {
      "metadata": {
        "id": "tESMhe5xyg70"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Model - Conv2D <a name=\"Conv2D\"></a>"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "fUlyILYlyg70"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(16,(3,3),activation = 'relu',input_shape = (244,244,3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32,(3,3),activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128,activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(256,activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(4,activation = 'softmax')\n",
        "\n",
        "],    name = 'Conv2D_Model')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "DGPjRjm_yg75"
      },
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 0.001 #@param {type:\"number\"}\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "KNFvML2tyg75"
      },
      "cell_type": "code",
      "source": [
        "EPOCHS=10 #@param {type:\"integer\"}\n",
        "\n",
        "history = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=validation_generator,\n",
        "        callbacks = [callbacks],\n",
        "        validation_steps=validation_generator.samples//validation_generator.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qBXbtOB7yg75"
      },
      "cell_type": "markdown",
      "source": [
        "### Metrics <a name=\"MetricsConv2D\"></a>"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "akxnleIQyg75"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IlPn_djSyg75"
      },
      "cell_type": "markdown",
      "source": [
        "#### Observing the Convolutions  <a name=\"ObservingConv2D\"></a>"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "DaJLHDxxyg75"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "\n",
        "# Lets define a new Model that will take an image as an input and will output\n",
        "# the intermediate representations for all layers in the previous model after\n",
        "# the first\n",
        "\n",
        "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
        "\n",
        "# Visualization_model = Model(img_input,successive_outputs)\n",
        "visualization_model = tf.keras.models.Model(inputs = model.input,\n",
        "                                            outputs = successive_outputs)\n",
        "\n",
        "# Lets prepare a random input image form the training set.\n",
        "\n",
        "BrownSpot_img_files = [os.path.join(train_BrownSpot_dir, f) for f in train_BrownSpot_names]\n",
        "Healthy_files = [os.path.join(train_Healthy_dir, f) for f in train_Healthy_names]\n",
        "img_path = random.choice(BrownSpot_img_files + Healthy_files)\n",
        "\n",
        "\n",
        "img = load_img(img_path,target_size = (244,244)) # This is a PIL image\n",
        "x = img_to_array(img)  # Numpy array with shape (244,244,3)\n",
        "x = x.reshape((1,) + x.shape) # Numpy array with shape (1,244,244,3)\n",
        "\n",
        "# Rescale by 1/255\n",
        "x /=255\n",
        "\n",
        "\n",
        "# Let's run our image through our network, thus obtaining all\n",
        "# Intermediate representations for this image.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# These are the names of the layers so we can have them as part of our plot\n",
        "layer_names = [layer.name for layer in model.layers[1:]]\n",
        "\n",
        "\n",
        "# Now lets display our representations\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  if len(feature_map.shape) == 4:\n",
        "    # Just do this for the conv/maxpool layers, for the fully-connected layers\n",
        "    n_features = feature_map.shape[-1] # number of features in feature map\n",
        "    # The feature map has shape (1,size,size,n_features)\n",
        "    size = feature_map.shape[1]\n",
        "    # We will title our images in this matrix\n",
        "    display_grid = np.zeros((size, size* n_features))\n",
        "    for i in range(n_features):\n",
        "      # Post process the feature to make it visibly palatable\n",
        "      x = feature_map[0,:,:,i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std()\n",
        "      x *= 64\n",
        "      x+= 128\n",
        "      x = np.clip(x,0,255).astype('uint8')\n",
        "      # We'll tile each filter into this big horizontal grid\n",
        "      display_grid[:,i*size:(i+1)*size] = x\n",
        "    # Display the grid\n",
        "    scale = 20. / n_features\n",
        "    plt.figure(figsize=(scale*n_features,scale))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid,aspect = 'auto', cmap = 'viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cu4KY0pGyg76"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.Model - Inception <a name=\"InceptionV3\"></a>"
      ]
    },
    {
      "metadata": {
        "id": "BA9_Lpfcyg76"
      },
      "cell_type": "markdown",
      "source": [
        "#### Downloading Weights <a name=\"DownloadWeights\"></a>"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "lgv6L7T-yg76"
      },
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf.dim_ordering_tf_kernels.notop.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "6064EVcqyg76"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf.dim_ordering_tf_kernels.notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(\n",
        "                                input_shape = (244,244,3),\n",
        "                                include_top= False,\n",
        "                                weights = None\n",
        ")\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Z2ChHp-uyg76"
      },
      "cell_type": "code",
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print(f'The shape of the last layer is {last_layer.output_shape}')\n",
        "output_layer = last_layer.output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "DhZY5_1syg76"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "x = tf.keras.layers.Flatten()(output_layer)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.4)(x)\n",
        "#x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x,name=\"RiceLeafs_Inception_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "SMbD46Z1yg76"
      },
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 0.001 #@param {type:\"number\"}\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr = LEARNING_RATE),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "a9vr4gGxyg76"
      },
      "cell_type": "code",
      "source": [
        "EPOCHS=10 #@param {type:\"integer\"}\n",
        "\n",
        "history = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=validation_generator,\n",
        "        callbacks = [callbacks],\n",
        "        validation_steps=validation_generator.samples//validation_generator.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lRgiSOhqyg77"
      },
      "cell_type": "markdown",
      "source": [
        "#### Metrics <a name=\"MetricsInceptionv3\"></a>"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "RWarimtyyg77"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DjwyTf-dyg77"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Model - EfficientNet v2 <a name=\"EfficientNet\"></a>"
      ]
    },
    {
      "metadata": {
        "id": "ntd8RLxtyg77"
      },
      "cell_type": "markdown",
      "source": [
        "#### TensorFlow Hub Dataset\n",
        "- [EfficientNet B7](https://tfhub.dev/tensorflow/efficientnet/b7/feature-vector/1)"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "SOWfIcTiyg77"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "model = tf.keras.Sequential([\n",
        "hub.KerasLayer(\"https://tfhub.dev/tensorflow/efficientnet/b7/feature-vector/1\"),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "\n",
        "  tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.build([None, 244, 244, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "cqVFj0hPyg77"
      },
      "cell_type": "code",
      "source": [
        "#Compile model specifying the optimizer learning rate\n",
        "\n",
        "LEARNING_RATE = 0.0001 #@param {type:\"number\"}\n",
        "\n",
        "model.compile(\n",
        "   optimizer=tf.keras.optimizers.Adam(lr=LEARNING_RATE),\n",
        "   loss='categorical_crossentropy',\n",
        "   metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "LMNZd8xVyg77"
      },
      "cell_type": "code",
      "source": [
        "EPOCHS=10 #@param {type:\"integer\"}\n",
        "\n",
        "history = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=validation_generator,\n",
        "        #callbacks = [callbacks],\n",
        "        validation_steps=validation_generator.samples//validation_generator.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nFZIPHU3yg77"
      },
      "cell_type": "markdown",
      "source": [
        "### Metrics <a name=\"MetricsEfficientv2\"></a>"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Rot6HRghyg77"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zImwaxXryg77"
      },
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "J5AX9BvMyg78"
      },
      "cell_type": "code",
      "source": [
        "IMAGE_SHAPE[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Qkt9ori5yg78"
      },
      "cell_type": "code",
      "source": [
        "# Import OpenCV\n",
        "import cv2\n",
        "\n",
        "# Utility\n",
        "import itertools\n",
        "import random\n",
        "from collections import Counter\n",
        "from glob import iglob\n",
        "\n",
        "\n",
        "def load_image(filename):\n",
        "    img = cv2.imread(os.path.join(data_dir, validation_dir, filename))\n",
        "    img = cv2.resize(img,(IMAGE_SHAPE[0], IMAGE_SHAPE[1]) )\n",
        "    img = img /255\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def predict(image):\n",
        "    probabilities = model.predict(np.asarray([img]))[0]\n",
        "    class_idx = np.argmax(probabilities)\n",
        "\n",
        "    return {classes[class_idx]: probabilities[class_idx]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "uiEZ7I4Zyg78"
      },
      "cell_type": "code",
      "source": [
        "for idx, filename in enumerate(random.sample(validation_generator.filenames, 5)):\n",
        "    print(\"SOURCE: class: %s, file: %s\" % (os.path.split(filename)[0], filename))\n",
        "\n",
        "    img = load_image(filename)\n",
        "    prediction = predict(img)\n",
        "    print(\"PREDICTED: class: %s, confidence: %f\" % (list(prediction.keys())[0], list(prediction.values())[0]))\n",
        "    plt.imshow(img)\n",
        "    plt.figure(idx)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sWnT9iznyg78"
      },
      "cell_type": "markdown",
      "source": [
        "# Export as TensorFlowLITE <a name=\"TFLITE\"></a>"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "TtIs7v7ayg78"
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "t = time.time()\n",
        "\n",
        "export_path = \"/tmp/saved_models/{}\".format(int(t))\n",
        "tf.keras.experimental.export_saved_model(model, export_path)\n",
        "\n",
        "export_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "F5ztXH-byg78"
      },
      "cell_type": "code",
      "source": [
        "# Now confirm that we can reload it, and it still gives the same results\n",
        "reloaded = tf.keras.experimental.load_from_saved_model(export_path, custom_objects={'KerasLayer':hub.KerasLayer}) # custom_objects depends on model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "23gRW0Wxyg78"
      },
      "cell_type": "code",
      "source": [
        "# convert the model to TFLite\n",
        "!mkdir \"tflite_models\"\n",
        "TFLITE_MODEL = \"tflite_models/rice_leaf_disease.tflite\"\n",
        "\n",
        "\n",
        "# Get the concrete function from the Keras model.\n",
        "run_model = tf.function(lambda x : reloaded(x))\n",
        "\n",
        "# Save the concrete function.\n",
        "concrete_func = run_model.get_concrete_function(\n",
        "    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype)\n",
        ")\n",
        "\n",
        "# Convert the model to standard TensorFlow Lite model\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "converted_tflite_model = converter.convert()\n",
        "open(TFLITE_MODEL, \"wb\").write(converted_tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}